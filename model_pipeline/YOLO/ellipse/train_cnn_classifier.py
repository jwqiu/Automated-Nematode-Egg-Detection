# train_cnn_classifier.py  ï¼ˆä¸ train/ å’Œ val/ åŒç›®å½•ï¼‰
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torchvision.transforms.functional as F
import shutil  # âœ… ç”¨äºå¤åˆ¶å’Œåˆ é™¤æ–‡ä»¶å¤¹
import random
import numpy as np
# æ­£æ–¹å½¢å¡«å……ï¼ˆä¸å˜å½¢ï¼‰ 

def set_seed(seed=42):
    """Set random seed for full reproducibility."""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

    # ä¿è¯ CuDNN å¯å¤ç°ï¼ˆä¼šç¨å¾®é™ä½é€Ÿåº¦ï¼‰
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

    os.environ["PYTHONHASHSEED"] = str(seed)

    print(f"ğŸ”’ Random seed set to {seed}")
    print("")

# è°ƒç”¨
set_seed(42)

class SquarePad:
    def __call__(self, img):
        w, h = img.size
        s = max(w, h)
        pad_left  = (s - w) // 2
        pad_top   = (s - h) // 2
        pad_right = s - w - pad_left
        pad_bottom= s - h - pad_top
        return F.pad(img, [pad_left, pad_top, pad_right, pad_bottom], fill=0)

# data transforms and get data loaders

def get_transforms(image_size=96, use_blur=True, brightness=0.3, contrast=0.3):
    """Return train and validation transform pipelines."""

    print("===== Data Transform Configuration =====")
    print(f"Image size: {image_size}")
    print(f"Use blur: {use_blur}")
    print(f"Brightness jitter: Â±{brightness}")
    print(f"Contrast jitter: Â±{contrast}")
    print("========================================")
    print("")

    transform_train_list = [
        transforms.Grayscale(1),
        SquarePad(),
        transforms.Resize(image_size),
        transforms.RandomRotation(10),
        transforms.RandomHorizontalFlip(0.5),
        transforms.RandomAffine(0, translate=(0.05, 0.05)),
        transforms.ColorJitter(brightness=brightness, contrast=contrast),
    ]
    if use_blur:
        transform_train_list.append(transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)))

    transform_train_list.append(transforms.ToTensor())

    transform_val = transforms.Compose([
        transforms.Grayscale(1),
        SquarePad(),
        transforms.Resize(image_size),
        transforms.ToTensor(),
    ])

    transform_train = transforms.Compose(transform_train_list)
    return transform_train, transform_val


# model definition

class EllipseCNN(nn.Module):
    def __init__(self, input_size=96, dropout=0.4, use_sigmoid_in_model=False,
                 extra_conv_layers=0, use_gap=False):
        """
        å‡çº§ç‰ˆ EllipseCNN
        -----------------
        å‚æ•°:
          input_size: è¾“å…¥å›¾ç‰‡å°ºå¯¸ (é»˜è®¤96)
          dropout: Dropout æ¯”ä¾‹
          use_sigmoid_in_model: æ˜¯å¦åœ¨æ¨¡å‹ä¸­åŠ  Sigmoid
          extra_conv_layers: é¢å¤–å¢åŠ çš„å·ç§¯å±‚æ•°é‡ï¼ˆé»˜è®¤0ä¸åŠ ï¼‰
          use_gap: æ˜¯å¦ä½¿ç”¨ Global Average Pooling æ›¿ä»£ Flatten
        """
        super().__init__()

        # ======== åŸºç¡€å·ç§¯å±‚ ========
        conv_blocks = [
            nn.Conv2d(1, 8, 3, 1, 1), nn.BatchNorm2d(8), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(8, 16, 3, 1, 1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, 1, 1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2)
        ]

        # ======== åŠ¨æ€å¢åŠ å·ç§¯å±‚ ========
        in_channels = 32
        for i in range(extra_conv_layers):
            out_channels = in_channels * 2 if in_channels < 256 else in_channels
            conv_blocks += [
                nn.Conv2d(in_channels, out_channels, 3, 1, 1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(),
                nn.MaxPool2d(2)
            ]
            in_channels = out_channels

        layers = conv_blocks

        # ======== å…¨è¿æ¥éƒ¨åˆ† ========
        if use_gap:
            layers += [
                nn.AdaptiveAvgPool2d(1),  # GAP å±‚
                nn.Flatten(),
                nn.Linear(in_channels, 64), nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(64, 1)
            ]
        else:
            fc_in = (input_size // (2 ** (3 + extra_conv_layers))) ** 2 * in_channels
            layers += [
                nn.Flatten(),
                nn.Linear(fc_in, 64), nn.ReLU(),
                nn.Dropout(dropout),
                nn.Linear(64, 1)
            ]

        # ======== è¾“å‡ºå±‚ ========
        if use_sigmoid_in_model:
            layers.append(nn.Sigmoid())

        self.net = nn.Sequential(*layers)

    def forward(self, x):
        return self.net(x)

# training components setup

def get_training_components(model, lr=5e-4, use_logits_loss=True, pos_weight=None):
    """
    Initialize model, criterion, optimizer, and scheduler.
    """
    # æŸ¥æ‰¾ Dropout å±‚ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    dropout_layers = [m for m in model.modules() if isinstance(m, nn.Dropout)]
    dropout_value = dropout_layers[0].p if dropout_layers else "N/A"

    print("===== Training Configuration =====")
    print(f"Learning rate: {lr}")
    print(f"Use logits loss: {use_logits_loss}")
    print(f"Pos weight: {pos_weight}")
    print(f"Model dropout: {dropout_value}")
    print("==================================")
    print("")

    # ====== Loss å‡½æ•° ======
    if use_logits_loss:
        if pos_weight is not None:
            pos_weight = torch.tensor([pos_weight])
            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
        else:
            criterion = nn.BCEWithLogitsLoss()
    else:
        criterion = nn.BCELoss()

    # ====== Optimizer ======
    optimizer = optim.Adam(model.parameters(), lr=lr)

    # ====== Scheduler ======
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=3
    )

    return model, criterion, optimizer, scheduler


# ========= 4) è®­ç»ƒ + éªŒè¯ï¼ˆå«æ—©åœï¼Œæ ¼å¼ä¿æŒåŸæ ·ï¼‰ =========

# ========= 1ï¸âƒ£ å®šä¹‰ train_one_epoch =========
def train_one_epoch(model, train_loader, criterion, optimizer, use_sigmoid):
    """å•è½®è®­ç»ƒï¼Œè¿”å› train_acc, train_loss"""
    model.train()
    total, correct, loss_sum = 0, 0, 0.0

    for imgs, labels in train_loader:
        preds = model(imgs).squeeze(1)
        loss = criterion(preds, labels.float())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        loss_sum += loss.item()
        total += labels.size(0)

        # âœ… åŠ¨æ€åˆ¤æ–­æ˜¯å¦éœ€è¦ sigmoidï¼ˆåªç”¨äºè®¡ç®—å‡†ç¡®ç‡ï¼Œä¸å½±å“ lossï¼‰
        if use_sigmoid:
            probs = torch.sigmoid(preds)
        else:
            probs = preds

        pred_classes = (probs > 0.5).long()
        correct += (pred_classes == labels).sum().item()

    train_acc = correct / total if total else 0.0
    return train_acc, loss_sum

# ========= 2ï¸âƒ£ å®šä¹‰ validate_one_epoch =========
def validate_one_epoch(model, val_loader, criterion, use_sigmoid=False):
    """å•è½®éªŒè¯ï¼Œè¿”å› val_acc, val_loss, recall, f1, bad_cases, val_logits_list, val_labels_list"""
    model.eval()
    vtotal, vcorrect = 0, 0
    bad_cases = []  # [(path, prob, true_label, pred_label)]
    vloss_sum = 0.0
    tp = fp = fn = 0

    val_preds_logits_list = []
    val_labels_list = []

    with torch.no_grad():
        for imgs, labels in val_loader:
            preds = model(imgs).squeeze(1)
            loss = criterion(preds, labels.float())
            vloss_sum += loss.item()

            if use_sigmoid:
                probs = torch.sigmoid(preds).detach().cpu()
            else:
                probs = preds.detach().cpu()

            val_preds_logits_list.append(preds.detach().cpu())
            val_labels_list.append(labels.detach().cpu())

            pred_classes = (probs > 0.5).long()
            y_true = labels.long().cpu()
            y_pred = pred_classes.cpu()

            tp += ((y_pred == 1) & (y_true == 1)).sum().item()
            fp += ((y_pred == 1) & (y_true == 0)).sum().item()
            fn += ((y_pred == 0) & (y_true == 1)).sum().item()
            vcorrect += (pred_classes == labels).sum().item()
            vtotal += labels.size(0)

            # é”™è¯¯æ ·æœ¬
            batch_start = vtotal - labels.size(0)
            for i in range(len(labels)):
                if pred_classes[i] != labels[i]:
                    img_path, _ = val_loader.dataset.samples[batch_start + i]
                    prob = probs[i].item()
                    bad_cases.append((img_path, prob, labels[i].item(), pred_classes[i].item()))

    val_acc = vcorrect / vtotal if vtotal else 0.
    val_loss = vloss_sum / max(1, len(val_loader))
    recall = tp / (tp + fn + 1e-9)
    f1 = 2 * tp / (2 * tp + fp + fn + 1e-9)

    return val_acc, val_loss, recall, f1, bad_cases, val_preds_logits_list, val_labels_list


def save_bad_cases(bad_cases, badcase_dir):
    """
    ä¿å­˜é”™è¯¯é¢„æµ‹æ ·æœ¬åˆ°æŒ‡å®šç›®å½•ã€‚
    æ–‡ä»¶åæ ¼å¼ç¤ºä¾‹: img001_0.43_T1_P0.png
    """
    # æ¸…ç©ºæ—§ç›®å½•
    if os.path.exists(badcase_dir):
        shutil.rmtree(badcase_dir)
    os.makedirs(badcase_dir, exist_ok=True)

    for src_path, prob, true_label, pred_label in bad_cases:
        base, ext = os.path.splitext(os.path.basename(src_path))
        dst_name = f"{base}_{prob:.2f}_T{true_label}_P{pred_label}{ext}"
        dst_path = os.path.join(badcase_dir, dst_name)
        shutil.copy(src_path, dst_path)

    print(f"ğŸ“‚ Saved {len(bad_cases)} bad cases to {badcase_dir} (after training)")


# ========= 3ï¸âƒ£ è®­ç»ƒä¸»å¾ªç¯ï¼ˆå«æ—©åœï¼‰ =========

# æ•°æ®è·¯å¾„
train_dir = "model_pipeline/YOLO/ellipse/train"
val_dir   = "model_pipeline/YOLO/ellipse/val"
model_path = "model_pipeline/YOLO/ellipse/ellipse_cnn.pt"
badcase_dir = "model_pipeline/YOLO/ellipse/badcase"

# ===== Data & Transform Config =====
input_size = 64         # å›¾åƒç¼©æ”¾å°ºå¯¸ (Resize)
use_blur = True          # æ˜¯å¦åœ¨æ•°æ®å¢å¼ºä¸­åŠ å…¥é«˜æ–¯æ¨¡ç³Š
brightness = 0.3         # äº®åº¦æ‰°åŠ¨å¹…åº¦
contrast = 0.3           # å¯¹æ¯”åº¦æ‰°åŠ¨å¹…åº¦

# ===== Model Architecture Config =====
dropout = 0.5           # Dropout æ¦‚ç‡ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
use_sigmoid_in_model = False      # æ˜¯å¦åœ¨æ¨¡å‹æœ€ååŠ  Sigmoid å±‚ï¼ˆè‹¥ä½¿ç”¨ BCEWithLogitsLossï¼Œåº”è®¾ä¸º Falseï¼‰
use_sigmoid_in_eval = not use_sigmoid_in_model  # æ˜¯å¦åœ¨éªŒè¯æ—¶æ‰‹åŠ¨åŠ 
use_logits_loss = not use_sigmoid_in_model  # æ˜¯å¦ä½¿ç”¨å¸¦ logits çš„ BCE æŸå¤±å‡½æ•°ï¼ˆæ¨èè®¾ä¸º Trueï¼‰
pos_weight = None       # æ­£æ ·æœ¬æƒé‡ï¼ˆä¸æŒ‡å®šåˆ™ä¸º Noneï¼‰
extra_conv_layers = 2   # é¢å¤–å·ç§¯å±‚æ•°é‡ï¼ˆ>=0ï¼‰
use_gap = False          # æ˜¯å¦ä½¿ç”¨ Global Average Pooling æ›¿ä»£ Flatten

# ===== Training Hyperparameters =====
epochs = 100             # æœ€å¤§è®­ç»ƒè½®æ¬¡
batch_size = 32          # æ‰¹æ¬¡å¤§å°
lr = 0.001              # å­¦ä¹ ç‡ (Learning rate)
patience = 15            # æ—©åœç­–ç•¥ (è¿ç»­å¤šå°‘è½®æ— æå‡åˆ™åœæ­¢)

# ===== Runtime & Tracking Config =====
best_val = 0.0           # è®°å½•æœ€ä½³éªŒè¯é›†æŸå¤±
wait = 0                 # æ—©åœè®¡æ•°å™¨
best_bad_cases = []      # å­˜å‚¨æœ€ä½³æ¨¡å‹ä¸‹çš„é”™è¯¯æ ·æœ¬

if __name__ == "__main__":  

    transform_train, transform_val = get_transforms(image_size=input_size, use_blur=use_blur, brightness=brightness, contrast=contrast)

    train_data = datasets.ImageFolder(root=train_dir, transform=transform_train)
    val_data   = datasets.ImageFolder(root=val_dir,   transform=transform_val)

    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False)

    # print("Class mapping:", train_data.class_to_idx)  # {'ellipse': 0, 'non_ellipse': 1}

    model = EllipseCNN(input_size=input_size, dropout=dropout, use_sigmoid_in_model=use_sigmoid_in_model,
                    extra_conv_layers=extra_conv_layers, use_gap=use_gap)

    model, criterion, optimizer, scheduler = get_training_components(
        model=model,
        lr=lr,
        use_logits_loss=use_logits_loss,
        pos_weight=pos_weight
    )

    for epoch in range(1, epochs + 1):
        # ===== train =====
        train_acc, loss_sum = train_one_epoch(model, train_loader, criterion, optimizer, use_sigmoid=use_sigmoid_in_eval)

        # ===== val =====
        val_acc, val_loss, recall, f1, bad_cases, val_preds_logits_list, val_labels_list = validate_one_epoch(model, val_loader, criterion, use_sigmoid=use_sigmoid_in_eval)

        print(f"Epoch {epoch:2d}: "
            f"TrainAcc={train_acc:.3f}  ValAcc={val_acc:.3f}  "
            f"ValLoss={val_loss:.4f}  Recall={recall:.3f}  F1={f1:.3f}  LossSum={loss_sum:.3f}")
        scheduler.step(val_loss)

        # ===== early stopping & ä¿å­˜æœ€ä½³æ¨¡å‹çš„é”™è¯¯æ ·æœ¬ï¼ˆç›‘æ§ val_loss è¶Šå°è¶Šå¥½ï¼‰=====
        if best_val == 0.0 or val_loss < best_val:
            best_val = val_loss
            best_f1 = f1
            best_epoch = epoch
            best_bad_cases = bad_cases.copy()
            wait = 0
            torch.save(model.state_dict(), model_path)
        else:
            wait += 1
            if wait >= patience:
                print("â¹ Early stopping triggered!")
                print(f"âœ… Best model found at Epoch {best_epoch} "
                    f"(ValLoss={best_val:.4f}, F1={best_f1:.3f})")
                break


    # ===== è®­ç»ƒç»“æŸæˆ–æ—©åœåå¤„ç† bad cases =====
    save_bad_cases(best_bad_cases, badcase_dir)


# ===== 5) å¯»æ‰¾æœ€ä½³é˜ˆå€¼ï¼ˆåŸºäºéªŒè¯é›†ï¼‰ =====
# val_preds_logits = torch.cat(val_preds_logits_list).cpu()
# val_labels = torch.cat(val_labels_list).cpu()

# thresholds = np.arange(0.3, 0.9, 0.02)
# best_thr, best_f1 = 0.5, 0
# for t in thresholds:
#     preds_bin = (torch.sigmoid(val_preds_logits) > t).int()
#     f1 = f1_score(val_labels, preds_bin)
#     if f1 > best_f1:
#         best_f1, best_thr = f1, t
# print(f"âœ… Best threshold = {best_thr:.2f}, F1 = {best_f1:.3f}")